# -*- coding: utf-8 -*-
"""xray-classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Q7NpXFNhLDUcBx2auot6j_1UkViGXJ-9
"""

# Commented out IPython magic to ensure Python compatibility.
# Import necessary dependencies
import os
import io
import cv2
import glob
import zipfile
import shutil
import random
import scipy.misc
import numpy as np
import pandas as pd
import matplotlib
import keras
import sklearn.metrics
import tensorflow as tf
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import applications
from keras.models import Sequential, load_model
from tensorflow.keras.optimizers.legacy import Adam
from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Flatten, Dense, Dropout

# Switch off potential warnings
import warnings
warnings.filterwarnings("ignore")

# %matplotlib inline

# Commented out IPython magic to ensure Python compatibility.
# Define the hyperparameters
LEARNING_RATE = 0.001
IMAGE_HEIGHT, IMAGE_WIDTH = 256, 256

url = "https://github.com/adleberg/medical-ai"

# Load image to array
def load_image_into_numpy_array(image):
    image = image.convert('RGB')
    (im_width, im_height) = image.size
    return np.array(image.getdata()).reshape(
        (im_height, im_width, 3)).astype(np.uint8)

# Download the dataset
print("Downloading...")

# %cd -q /content
repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(url)))
!git clone {url} --quiet
# %cd -q {repo_dir_path}
!git pull -q

print("Done!")

df = pd.read_csv("/content/medical-ai/labels.csv")
df.head(5)

df["label"].unique() # Check unique labels

# Seperate to classes
class_names = []

for name in df["label"].unique():
  class_ = name.lower()
  class_ = df.loc[df["label"] == name]
  class_names.append(name)
  print(f"{name}: {len(class_)} examples")

test_ratio = 0.2
root_dir = "/content/medical-ai"
train_dir = "/content/medical-ai/train"
test_dir = "/content/medical-ai/test"

# Create train and test directories
os.makedirs(train_dir, exist_ok=True)
os.makedirs(test_dir, exist_ok=True)

# List all images in the root directory
images = [f for f in os.listdir(root_dir+"/images/") if f.endswith(".jpg")]  # Adjust the file extension as needed

# Calculate the number of images for testing based on the test ratio
num_test_images = int(len(images) * test_ratio)

# Randomly shuffle the images
random.shuffle(images)

# Split the images into train and test sets
train_images = images[num_test_images:]
test_images = images[:num_test_images]

# Move images to the train and test directories without class subfolders
for image in train_images:
    src_path = os.path.join(root_dir+"/images/", image)
    dest_path = os.path.join(train_dir, image)
    shutil.move(src_path, dest_path)

for image in test_images:
    src_path = os.path.join(root_dir+"/images/", image)
    dest_path = os.path.join(test_dir, image)
    shutil.move(src_path, dest_path)

train_path = "/content/medical-ai/train"
test_path = "/content/medical-ai/test"

# Data augmentation and pre-processing
gen = ImageDataGenerator(
    rescale=1./255.,
    horizontal_flip=True,
    validation_split=0.25,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
)

train_generator = gen.flow_from_dataframe(
    df,
    directory=train_path,
    x_col="filename",
    y_col="label",
    subset="training",
    color_mode="rgb",
    target_size=(256, 256),
    class_mode="categorical",
    batch_size=32,
    shuffle=True,
    seed=42
)

validation_generator = gen.flow_from_dataframe(
    df,
    directory=train_path,
    x_col="filename",
    y_col="label",
    subset="validation",
    color_mode="rgb",
    target_size=(256, 256),
    class_mode="categorical",
    batch_size=32,
    shuffle=True,
    seed=42
)

x, y = next(train_generator)
x.shape # Input shape of one record

def plot_images(img, labels):
  plt.figure(figsize=(15, 10))
  for i in range(25):
    plt.subplot(5, 5, i+1)
    plt.imshow(img[i])
    plt.title(class_names[np.argmax(labels[i])])
    plt.axis("off")

plot_images(x, y)

# Load the InceptionResNetV2 architecture
base_model = tf.keras.applications.InceptionResNetV2(
    include_top=False,
    weights="imagenet",
    input_shape=(256, 256, 3)
)

base_model.trainable=False

model = tf.keras.Sequential([
    base_model,
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dense(9, activation='sigmoid')
])

# Define custom optimizer
custom_optimizer = Adam(learning_rate=LEARNING_RATE)

model.compile(optimizer=custom_optimizer, loss="categorical_crossentropy", metrics=["accuracy"])

model.summary()

early = tf.keras.callbacks.EarlyStopping(patience=10,
                                        min_delta=0.001,
                                        restore_best_weights=True)

# Fit the model
batch_size=32
STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size
STEP_SIZE_VALID = validation_generator.n//validation_generator.batch_size

history = model.fit(train_generator,
                    steps_per_epoch=STEP_SIZE_TRAIN,
                    validation_data=validation_generator,
                    validation_steps=STEP_SIZE_VALID,
                    epochs=25,
                    callbacks=[early])

# Store results
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

# Plot results
plt.figure(figsize=(10, 16))
plt.rcParams['figure.figsize'] = [16, 9]
plt.rcParams['font.size'] = 14
plt.rcParams['axes.grid'] = True
plt.rcParams['figure.facecolor'] = 'white'
plt.subplot(2, 1, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.ylabel('Accuracy')
plt.title(f'\nTraining and Validation Accuracy. \nTrain Accuracy: {str(acc[-1])}\nValidation Accuracy: {str(val_acc[-1])}')

plt.subplot(2, 1, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.ylabel('Cross Entropy')
plt.title(f'Training and Validation Loss. \nTrain Loss:{str(loss[-1])}\nValidation Loss: {str(val_loss[-1])}')
plt.xlabel('epoch')
plt.tight_layout(pad=3.0)
plt.show()

accuracy_score = model.evaluate(validation_generator)
print(accuracy_score)
print("Accuracy: {:.4f}%".format(accuracy_score[1] * 100))

print("Loss: ",accuracy_score[0])

# Create a subplot to display the images
plt.figure(figsize=(8, 12))

for i, image_filename in enumerate(selected_images, 1):
    # Load the image
    img = tf.keras.preprocessing.image.load_img(os.path.join(test_path, image_filename))

    # Convert the image to a NumPy array
    img = tf.keras.preprocessing.image.img_to_array(img)

    # Resize the image (if needed)
    img = tf.keras.preprocessing.image.smart_resize(img, (256, 256))

    # Reshape the image to match the model's input shape
    img = tf.reshape(img, (-1, 256, 256, 3))

    # Make predictions (assuming 'model' is your trained model)
    prediction = model.predict(img / 255)  # Normalize pixel values
    predicted_class = np.argmax(prediction)

    # Display the image with its true and predicted labels
    plt.subplot(2, 3, i)
    plt.imshow(img[0] / 255)  # Display the image (don't forget to normalize)
    plt.title(f"True: {image_filename}\nPredicted: Class {predicted_class}", pad=20)  # Add padding to the title
    plt.axis('off')

# Show the plot with up to 6 images
plt.tight_layout()
plt.show()

model.save("xray-classifier.h5")

!cp /content/medical-ai/xray-classifier.h5 /content/drive/MyDrive/xray-classifier